jobs: 1

symbol_types:
  - predicate


# Dataset

problems:
  # List of problem path glob patterns
  # TPTP problem naming: http://www.tptp.org/TPTP/TR/TPTPTR.shtml
  patterns:
    - "**/*-*.p" # CNF
    - "**/*+*.p" # FOF
  # List of problem names. Overrides the option `problem`.
  names: null
  train: null
  val: null
  max_count: null

validation_split: 0.5

batch_size:
  train: 128
  val: 256

questions:
  dir: null
  dir_legacy: null
  max_count: null
  max_per_problem: null
  hoeffding_exponent: 4.0
  batch_size: 1000
  randomize:
    - predicate
  normalize: true


# Model

symbol_cost:
  # Choices: gcn, simple, direct, baseline
  model: gcn
  # Factor of L2 regularization penalty on symbol cost values
  l2: 0.0

# GCN
gcn:
  depth: 4
  message_size: 16
  activation: relu
  aggregate: sum
  dropout:
    input: null
    hidden: null
  max_norm: null
  residual: true
  layer_norm: true
  # If 'custom', use a recommended normalization for each edge type.
  # Choices: both, right, none, custom
  conv_norm: both
  max_problem_nodes:
    train: 100000
    val: 100000

embedding_to_cost:
  hidden:
    units: 0
    activation: relu
  l1: 0.0
  l2: 0.0

# List of 12 weights of the simple model
simple_model_kernel: null

# Path to a checkpoint to restore
restore_checkpoint:
  predicate: null
  function: null


# Training

# Choices: adam, sgd, rmsprop
optimizer: adam
# Before training the learning rate is multiplied by `batch_size.train`.
learning_rate: 0.00001
epochs: 1000

reduce_lr_on_plateau:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau
  monitor: loss
  factor: 0.5
  patience: 10
  verbose: 1

early_stopping:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping
  monitor: val_binary_accuracy
  patience: 100
  baseline: 0.5


# Evaluation

initial_eval: true
initial_evaluation_extra: false

solver_eval:
  start: null
  step: null
  iterations: 1
  cache: false
  isolated: false
  problems:
    train: 1000
    val: 1000
  batch_size: 1000
  train_without_questions: false
  problem_set: []
  baselines: {}


# Advanced configuration

solver:
  # Options passed to Vampire.
  # Run `vampire --show_options on --show_experimental_options on` to print the available options.
  # Example: {time_limit: 10}
  options:
    encode: "on"
    statistics: full
    time_statistics: "on"
    proof: "off"
    avatar: "off"
    saturation_algorithm: discount
    age_weight_ratio: 10
    literal_comparison_mode: predicate
    symbol_precedence: frequency
    time_limit: 10
  # Time in seconds after which each call to Vampire is terminated.
  timeout: 20

clausifier:
  options:
    encode: "on"
    time_limit: 300
  timeout: null

neptune:
  project_qualified_name: filipbartek/vampire-ml
  experiment:
    name: null
    tags: null
    upload_source_files:
      - requirements.txt
      - questions/config.yaml
      - questions/**/*.py
      - proving/**/*.py
      - vampire_ml/**/*.py

tf:
  # https://www.tensorflow.org/api_docs/python/tf/config/run_functions_eagerly
  run_eagerly: false
  # https://www.tensorflow.org/api_docs/python/tf/config/threading
  threads:
    inter: 0
    intra: 0

# TensorBoard
tb:
  profile_batch: 0

# Python default is 1000. 10000 is enough to parse all TPTP problems.
recursion_limit: 10000

# Choices: INFO, DEBUG
log_level: INFO
