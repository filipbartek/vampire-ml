defaults:
  - _self_
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

seed: 0
eras: 10
epochs_per_era: 10
validation_split: 0.5
max_problem_count: null
evaluate:
  baseline: true
  initial: true
proof_sample_weight: 0.5

# Maximum proof output file size in bytes
max_proof_stdout_size: 100000000

workspace_dir: null
vampire_cmd: vampire
problems: null
tptp_path: null

options:
  common:
    include: ${tptp_path}
    avatar: "off"
    # The default saturation algorithm LRS does not currently support custom functor weights.
    saturation_algorithm: discount
  probe:
    proof: "off"
    instruction_limit: 50000
  verbose:
    #show_everything: "on"
    show_active: "on"
    proof_extra: free
  evaluation:
    default: {}
    #awr_0_1:
    #  age_weight_ratio: "0:1"
    #awr_1_9:
    #  age_weight_ratio: "1:9"

probe_run_args:
  # Choices: subprocess, benchexec
  backend: subprocess

  # subprocess: The parameters are passed to `subprocess.run`.
  timeout: 60

  # BenchExec: The arguments are passed to `benchexec.runexecutor.RunExecutor.execute_run`.
  # Notable parameters: softtimelimit, hardtimelimit, walltimelimit
  # Documentation: https://github.com/sosy-lab/benchexec/blob/main/doc/runexec.md

batch:
  size: 128
  count: 1

parallel:
  backend: loky
  n_jobs: 1
  verbose: 1

gcn:
  depth: 4
  message_size: 16
  activation: relu
  aggregate: sum
  dropout:
    input: null
    hidden: null
  max_norm: null
  residual: true
  layer_norm: true
  # If 'custom', use a recommended normalization for each edge type.
  # Choices: both, right, none, custom
  conv_norm: both
  max_problem_nodes:
    train: 100000
    val: 100000

embedding_to_cost:
  hidden:
    units: 0
    activation: relu
  l1: 0.0
  l2: 0.0

symbol_cost:
  # Factor of L2 regularization penalty on symbol cost values
  l2: 0.0

# Choices: adam, sgd, rmsprop
optimizer: adam
# Before training the learning rate is multiplied by `batch_size.train`.
learning_rate: 0.00001

tf:
  run_eagerly: false
  threads:
    inter: 0
    intra: 0

reduce_lr_on_plateau:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau
  monitor: loss
  factor: 0.5
  patience: 10
  verbose: 1

early_stopping:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping
  monitor: val_binary_accuracy
  patience: 100
  baseline: 0.5
