defaults:
  - _self_
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

hydra:
  job:
    chdir: true
    env_set:
      DGLBACKEND: tensorflow
      TF_CPP_MIN_LOG_LEVEL: 1
      # Python default: 1000
      RECURSIONLIMIT: 10000
      # TF_NUM_INTEROP_THREADS: 0
      # TF_NUM_INTRAOP_THREADS: 0

seed: 0
epochs: null
train_ratio: 0.5
max_problem_count: null
eval:
  baseline: true
  initial: true
proof_sample_weight: 0.5
baseline_files: {}
empirical:
  start: -1
  step: 10
per_problem_stats: false

checkpoint:
  # Path to checkpoint to initialize the model with
  restore: null
  directory: tf_ckpts
  manager:
    # https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager
    directory: ${checkpoint.directory}/latest
    max_to_keep: 3

proof:
  # Maximum proof output file size in bytes
  max_size: 100000000
  max_clauses:
    proof: 1000
    nonproof: 1000
  max_symbols: 1000
  selection_queues:
    # Only use clauses selected from the specified queues.
    # Options: w, a
    - w
    - a

# Choices: literal_positive, literal_negative, equality, inequality, variable_occurrence, variable_count, number
clause_features:
  - variable_occurrence
  - equality

workspace_dir: null
vampire_cmd: ${oc.env:VAMPIRE}
problem:
  list_file: ${workspace_dir}/problems.txt
  names: []
  patterns: []
  # If null, use the longest common sub-path of all the problem paths.
  # If not null, must be a sub-path of all problem paths.
  # Problem paths may be specified as relative with respect to root.
  root_dir: null
  # If not null, subsample the problems to at most this number.
  max_count: null
  # If set, it should be a mapping from [train, val] to problem list filenames.
  dataset:
    train: null
    val: null
tptp_path: ${oc.env:TPTP}

options:
  common:
    input_syntax: tptp
    avatar: "off"
    # The default saturation algorithm LRS does not currently support custom functor weights.
    saturation_algorithm: discount
    age_weight_ratio: "1:5"
    statistics: full
    time_limit: 300
  probe:
    proof: "off"
    instruction_limit: 50000
  verbose:
    #show_everything: "on"
    show_active: "on"
    proof_extra: free
  evaluation:
    default: {}
    #awr_0_1:
    #  age_weight_ratio: "0:1"
    #awr_1_9:
    #  age_weight_ratio: "1:9"

probe_run_args:
  # Choices: subprocess, benchexec
  backend: subprocess

  # subprocess: The parameters are passed to `subprocess.run`.
  timeout: 310

  # BenchExec: The arguments are passed to `benchexec.runexecutor.RunExecutor.execute_run`.
  # Notable parameters: softtimelimit, hardtimelimit, walltimelimit
  # Documentation: https://github.com/sosy-lab/benchexec/blob/main/doc/runexec.md

batch:
  size: 64
  count: 1

parallel:
  # Choices: loky, threading, multiprocessing
  backend: loky
  n_jobs: 1
  verbose: 1

gcn:
  depth: 4
  message_size: 16
  activation: relu
  # Options: concat, sum
  aggregate: sum
  dropout:
    input: null
    hidden: null
  max_norm: null
  residual: true
  layer_norm: true
  # If 'custom', use a recommended normalization for each edge type.
  # Choices: both, right, none, custom
  conv_norm: both
  max_problem_nodes:
    train: 100000
    val: 100000

max_problem_nodes: 100000

embedding_to_cost:
  # TODO: Support deeper MLPs.
  # Choices: softplus, linear, null, relu, exponential, sigmoid, tanh
  activation: softplus
  output_bias: 1
  regularization:
    l1: 0.0
    l2: 0.0

symbol_cost:
  # Factor of L2 regularization penalty on symbol cost values
  l2: 0.0

# Choices: adam, sgd, rmsprop
optimizer: adam
learning_rate: 0.001

tf:
  device: null
  run_eagerly: false
  log_device_placement: false

tensorboard:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard
  log_dir: logs
  histogram_freq: 1
  profile_batch: 0
  embeddings_freq: 1

reduce_lr_on_plateau:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau
  monitor: loss
  factor: 0.5
  patience: 10
  verbose: 1

early_stopping:
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping
  monitor: val_binary_accuracy
  patience: 100
  baseline: 0.5
